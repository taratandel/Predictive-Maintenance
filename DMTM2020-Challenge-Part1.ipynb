{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Challenge 2020\n",
    "\n",
    "## Team\n",
    "* First-name Last-name Student-ID\n",
    "* ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# section one \n",
    "apply the desired libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Statistical libraries\n",
    "from scipy import stats\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Evaluation Procedures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Classification methods\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section two\n",
    "Defin the functions that we will use through out our code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the confusion Matrix\n",
    "def PrintConfusionMatrix(model, true_y, predicted_y, positive=1, negative=-1):\n",
    "    cm = confusion_matrix(true_y,predicted_y)\n",
    "    print(\"\\t\"+str(model.classes_[0])+\"\\t\"+str(model.classes_[1]))\n",
    "    print(str(model.classes_[0]) + \"\\t\",cm[0][0],\"\\t\",cm[0][1])\n",
    "    print(str(model.classes_[1]) + \"\\t\",cm[1][0],\"\\t\",cm[1][1])    \n",
    "\n",
    "def PrintSignificance(stat, c):\n",
    "    if (stat[1]<(1-c)):\n",
    "        print(\"The difference is statistically significant (cf %3.2f p-value=%.4f)\"%(c,stat[1]))\n",
    "    else:\n",
    "        print(\"The difference is not statistically significant (cf %3.2f p-value=%.4f)\"%(c,stat[1]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training \n",
    "def train_model(methods, x_t,y_t, x_te, y_te):\n",
    "    xval_results = {}\n",
    "    roc_results = {}\n",
    "    feature_importance_model = {}\n",
    "\n",
    "    method = []\n",
    "    accuracy_mean = []\n",
    "    accuracy_std = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    auc = []\n",
    "\n",
    "    for method_name in methods:\n",
    "\n",
    "\n",
    "        clf = methods[method_name];\n",
    "\n",
    "        # evaluate the model using crossvalidation\n",
    "        xval_score = cross_val_score(clf,X,y,cv=crossvalidation)\n",
    "\n",
    "        # store the raw results of crossvalidation that we might want to use for t-test/mann-whitney comparison\n",
    "        xval_results[method_name] = xval_score\n",
    "\n",
    "        # compute the basic statistics\n",
    "        accuracy_mean.append(np.average(xval_score))\n",
    "        accuracy_std.append(np.std(xval_score))\n",
    "\n",
    "        clf.fit(x_t,y_t)\n",
    "\n",
    "        # if the mode can return an evaluation of feature importance we store it to analyze it later\n",
    "        if hasattr(clf, 'feature_importances_'):\n",
    "                feature_importance_model[method_name] = (clf,clf.feature_importances_)\n",
    "\n",
    "        # compute the prediction which, for probabilistic classifiers, is using a threshold of 0.5\n",
    "        yp = clf.predict(x_te)\n",
    "\n",
    "        # ask for the probability values\n",
    "        yprob = clf.predict_proba(x_te)\n",
    "\n",
    "        # computes the data needed to draw the ROC curve\n",
    "        fpr_nb, tpr_nb, thresholds = roc_curve(y_true=y_te, y_score = yprob[:,1], pos_label=1)\n",
    "\n",
    "        # computes the AUC \n",
    "        roc_auc = roc_auc_score(y_true=y_te, y_score = yprob[:,1])\n",
    "        auc.append(roc_auc)\n",
    "\n",
    "        # store the information to plot the ROC curves afterwards\n",
    "        roc_results[method_name] = (fpr_nb, tpr_nb, thresholds, roc_auc)\n",
    "\n",
    "        precision.append(precision_score(y_te,yp))\n",
    "        recall.append(recall_score(y_te,yp))\n",
    "        f1.append(f1_score(y_te, yp))\n",
    "\n",
    "        print(\"%40s\"%method_name)\n",
    "        print(\"========================================\")\n",
    "        print(\"\\t  Accuracy (CV) %.3f %.3f\"%(np.average(xval_score),np.std(xval_score)))\n",
    "        print(\"\\tAccuracy (Test) %.3f\"%precision_score(y_test, yp))\n",
    "        print(\"\\t      Precision %.3f\"%precision_score(y_test, yp))\n",
    "        print(\"\\t      Recall    %.3f\"%recall_score(y_test, yp))\n",
    "        print(\"\\t      F1        %.3f\"%f1_score(y_test, yp))\n",
    "        print(\"\\n\")\n",
    "\n",
    "        method.append(method_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section Three \n",
    "Apply data preprocessing we can see that the categorical datas are already One-Hot encoded \n",
    "\n",
    "### 3.1 loading the data and split test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Data Quality assurnace \n",
    "we should check for:\n",
    "\n",
    "3.2.1- null and missing values \n",
    "\n",
    "3.2.2- inconsistant values \n",
    "\n",
    "3.2.3- duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for the null \n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see that there are no NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check for inconsistent values\n",
    "First we take the range and variance for each column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_max = df.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_min = df.min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CELL_TYPE_TRP                             0.0\n",
       "CELL_TYPE_Macro                           1.0\n",
       "aircon_sum_target_next14d                 1.0\n",
       "GEOGRAPHIC_CLUSTER_K_9                    1.0\n",
       "GEOGRAPHIC_CLUSTER_K_8                    1.0\n",
       "                                       ...   \n",
       "ge_max_persistance_prev7d             30775.0\n",
       "temperature_max_persistance_prev7d    36867.0\n",
       "temperature_max_persistance_prev3d    36867.0\n",
       "equipment_max_persistance_prev7d      58584.0\n",
       "equipment_max_persistance_prev3d      58584.0\n",
       "Length: 134, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_range = col_max - col_min\n",
    "df_range.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['CELL_TYPE_TRP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kurt_fire/smoke_alarms_prev14d       -1.207066\n",
       "kurt_ge_alarms_prev14d               -1.205633\n",
       "kurt_temperature_alarms_prev14d      -1.196703\n",
       "kurt_equipment_alarms_prev14d        -1.187480\n",
       "kurt_power_alarms_prev14d            -1.159289\n",
       "                                      ...     \n",
       "mean_pressure_f_next7d             1016.819736\n",
       "max_pressure_prev3d                1019.411511\n",
       "max_pressure_prev7d                1022.051804\n",
       "max_pressure_f_next7d              1022.214006\n",
       "max_pressure_f_next14d             1024.841812\n",
       "Length: 133, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean = df.mean()\n",
    "df_mean.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we can see here the 'CELL_TYPE_TRP' has the value zero so we drop it. but for the temprature the number 36867 is to big so we try th variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CELL_TYPE_Mobil                             0.000965\n",
       "skew_fire/smoke_alarms_prev14d              0.002947\n",
       "skew_ge_alarms_prev14d                      0.004884\n",
       "kurt_fire/smoke_alarms_prev14d              0.005571\n",
       "aircon_sum_target_next14d                   0.005734\n",
       "                                           ...      \n",
       "temperature_mean_persistance_prev7d     68996.395061\n",
       "temperature_mean_persistance_prev3d     77769.601536\n",
       "equipment_max_persistance_prev7d        98300.636563\n",
       "temperature_max_persistance_prev3d     184014.394985\n",
       "temperature_max_persistance_prev7d     293743.458247\n",
       "Length: 133, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_var = df.var()\n",
    "df_var.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CELL_TYPE_Mobil                          0.031061\n",
       "skew_fire/smoke_alarms_prev14d           0.054284\n",
       "skew_ge_alarms_prev14d                   0.069885\n",
       "kurt_fire/smoke_alarms_prev14d           0.074639\n",
       "aircon_sum_target_next14d                0.075721\n",
       "                                          ...    \n",
       "temperature_mean_persistance_prev7d    262.671649\n",
       "temperature_mean_persistance_prev3d    278.872016\n",
       "equipment_max_persistance_prev7d       313.529323\n",
       "temperature_max_persistance_prev3d     428.968991\n",
       "temperature_max_persistance_prev7d     541.981050\n",
       "Length: 133, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_std = df.std()\n",
    "df_std.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CELL_TYPE_Mobil                        0.000039\n",
       "skew_fire/smoke_alarms_prev14d         0.000069\n",
       "skew_ge_alarms_prev14d                 0.000089\n",
       "kurt_fire/smoke_alarms_prev14d         0.000095\n",
       "aircon_sum_target_next14d              0.000096\n",
       "                                         ...   \n",
       "temperature_mean_persistance_prev7d    0.333244\n",
       "temperature_mean_persistance_prev3d    0.353797\n",
       "equipment_max_persistance_prev7d       0.397766\n",
       "temperature_max_persistance_prev3d     0.544221\n",
       "temperature_max_persistance_prev7d     0.687596\n",
       "Length: 133, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sem = df.sem()\n",
    "df_sem.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be inconsistent if there is an irrelevant value so we should print all of them to se if there is some inconsistency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SITE_ID                                  int64\n",
      "DATE                                    object\n",
      "CELL_TYPE_Macro                          int64\n",
      "CELL_TYPE_Mobil                          int64\n",
      "CELL_TYPE_TRP                            int64\n",
      "CELL_TYPE_Tx site                        int64\n",
      "CELL_TYPE_micro                          int64\n",
      "N_TRANSPORTED_SITES                    float64\n",
      "GEOGRAPHIC_CLUSTER_K_0                   int64\n",
      "GEOGRAPHIC_CLUSTER_K_1                   int64\n",
      "GEOGRAPHIC_CLUSTER_K_2                   int64\n",
      "GEOGRAPHIC_CLUSTER_K_3                   int64\n",
      "GEOGRAPHIC_CLUSTER_K_4                   int64\n",
      "GEOGRAPHIC_CLUSTER_K_5                   int64\n",
      "GEOGRAPHIC_CLUSTER_K_6                   int64\n",
      "GEOGRAPHIC_CLUSTER_K_7                   int64\n",
      "GEOGRAPHIC_CLUSTER_K_8                   int64\n",
      "GEOGRAPHIC_CLUSTER_K_9                   int64\n",
      "aircon_sum_wo_prev7d                   float64\n",
      "aircon_sum_wo_prev14d                  float64\n",
      "aircon_sum_target_next14d                int64\n",
      "mean_temperature_prev7d                float64\n",
      "max_temperature_prev7d                 float64\n",
      "min_temperature_prev7d                 float64\n",
      "mean_temperature_prev3d                float64\n",
      "max_temperature_prev3d                 float64\n",
      "min_temperature_prev3d                 float64\n",
      "mean_rain_mm_prev7d                    float64\n",
      "max_rain_mm_prev7d                     float64\n",
      "min_rain_mm_prev7d                     float64\n",
      "mean_rain_mm_prev3d                    float64\n",
      "max_rain_mm_prev3d                     float64\n",
      "min_rain_mm_prev3d                     float64\n",
      "mean_humidity_prev7d                   float64\n",
      "max_humidity_prev7d                    float64\n",
      "min_humidity_prev7d                    float64\n",
      "mean_humidity_prev3d                   float64\n",
      "max_humidity_prev3d                    float64\n",
      "min_humidity_prev3d                    float64\n",
      "mean_wind_speed_prev7d                 float64\n",
      "max_wind_speed_prev7d                  float64\n",
      "min_wind_speed_prev7d                  float64\n",
      "mean_wind_speed_prev3d                 float64\n",
      "max_wind_speed_prev3d                  float64\n",
      "min_wind_speed_prev3d                  float64\n",
      "mean_pressure_prev7d                   float64\n",
      "max_pressure_prev7d                    float64\n",
      "min_pressure_prev7d                    float64\n",
      "mean_pressure_prev3d                   float64\n",
      "max_pressure_prev3d                    float64\n",
      "min_pressure_prev3d                    float64\n",
      "mean_temperature_f_next14d             float64\n",
      "max_temperature_f_next14d              float64\n",
      "min_temperature_f_next14d              float64\n",
      "mean_temperature_f_next7d              float64\n",
      "max_temperature_f_next7d               float64\n",
      "min_temperature_f_next7d               float64\n",
      "mean_rain_mm_f_next14d                 float64\n",
      "max_rain_mm_f_next14d                  float64\n",
      "min_rain_mm_f_next14d                  float64\n",
      "mean_rain_mm_f_next7d                  float64\n",
      "max_rain_mm_f_next7d                   float64\n",
      "min_rain_mm_f_next7d                   float64\n",
      "mean_humidity_f_next14d                float64\n",
      "max_humidity_f_next14d                 float64\n",
      "min_humidity_f_next14d                 float64\n",
      "mean_humidity_f_next7d                 float64\n",
      "max_humidity_f_next7d                  float64\n",
      "min_humidity_f_next7d                  float64\n",
      "mean_wind_speed_f_next14d              float64\n",
      "max_wind_speed_f_next14d               float64\n",
      "min_wind_speed_f_next14d               float64\n",
      "mean_wind_speed_f_next7d               float64\n",
      "max_wind_speed_f_next7d                float64\n",
      "min_wind_speed_f_next7d                float64\n",
      "mean_pressure_f_next14d                float64\n",
      "max_pressure_f_next14d                 float64\n",
      "min_pressure_f_next14d                 float64\n",
      "mean_pressure_f_next7d                 float64\n",
      "max_pressure_f_next7d                  float64\n",
      "min_pressure_f_next7d                  float64\n",
      "equipment_sum_alarms_prev14d           float64\n",
      "fire/smoke_sum_alarms_prev14d          float64\n",
      "ge_sum_alarms_prev14d                  float64\n",
      "power_sum_alarms_prev14d               float64\n",
      "temperature_sum_alarms_prev14d         float64\n",
      "equipment_sum_alarms_prev7d            float64\n",
      "fire/smoke_sum_alarms_prev7d           float64\n",
      "ge_sum_alarms_prev7d                   float64\n",
      "power_sum_alarms_prev7d                float64\n",
      "temperature_sum_alarms_prev7d          float64\n",
      "equipment_sum_alarms_prev3d            float64\n",
      "fire/smoke_sum_alarms_prev3d           float64\n",
      "ge_sum_alarms_prev3d                   float64\n",
      "power_sum_alarms_prev3d                float64\n",
      "temperature_sum_alarms_prev3d          float64\n",
      "equipment_max_persistance_prev7d       float64\n",
      "equipment_mean_persistance_prev7d      float64\n",
      "equipment_min_persistance_prev7d       float64\n",
      "fire/smoke_max_persistance_prev7d      float64\n",
      "fire/smoke_mean_persistance_prev7d     float64\n",
      "fire/smoke_min_persistance_prev7d      float64\n",
      "ge_max_persistance_prev7d              float64\n",
      "ge_mean_persistance_prev7d             float64\n",
      "ge_min_persistance_prev7d              float64\n",
      "power_max_persistance_prev7d           float64\n",
      "power_mean_persistance_prev7d          float64\n",
      "power_min_persistance_prev7d           float64\n",
      "temperature_max_persistance_prev7d     float64\n",
      "temperature_mean_persistance_prev7d    float64\n",
      "temperature_min_persistance_prev7d     float64\n",
      "equipment_max_persistance_prev3d       float64\n",
      "equipment_mean_persistance_prev3d      float64\n",
      "equipment_min_persistance_prev3d       float64\n",
      "fire/smoke_max_persistance_prev3d      float64\n",
      "fire/smoke_mean_persistance_prev3d     float64\n",
      "fire/smoke_min_persistance_prev3d      float64\n",
      "ge_max_persistance_prev3d              float64\n",
      "ge_mean_persistance_prev3d             float64\n",
      "ge_min_persistance_prev3d              float64\n",
      "power_max_persistance_prev3d           float64\n",
      "power_mean_persistance_prev3d          float64\n",
      "power_min_persistance_prev3d           float64\n",
      "temperature_max_persistance_prev3d     float64\n",
      "temperature_mean_persistance_prev3d    float64\n",
      "temperature_min_persistance_prev3d     float64\n",
      "skew_equipment_alarms_prev14d          float64\n",
      "skew_fire/smoke_alarms_prev14d         float64\n",
      "skew_ge_alarms_prev14d                 float64\n",
      "skew_power_alarms_prev14d              float64\n",
      "skew_temperature_alarms_prev14d        float64\n",
      "kurt_equipment_alarms_prev14d          float64\n",
      "kurt_fire/smoke_alarms_prev14d         float64\n",
      "kurt_ge_alarms_prev14d                 float64\n",
      "kurt_power_alarms_prev14d              float64\n",
      "kurt_temperature_alarms_prev14d        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the duplicates if any \n",
    "df.drop_duplicates()\n",
    "# drop the unused columns\n",
    "df = df.drop(columns=['SITE_ID','DATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have no duplicates if any "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the targer and input\n",
    "target_variable = 'aircon_sum_target_next14d'\n",
    "input_variables = df.columns[df.columns!=target_variable]\n",
    "\n",
    "X = df[input_variables]\n",
    "y = df[target_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed the random set to be consistant \n",
    "np.random.seed(1234)\n",
    "# do the train test splitting\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y,\\\n",
    "    test_size= 1/3.0, random_state =1234, shuffle=True)\n",
    "# cross validation using k-fold here 10\n",
    "crossvalidation = StratifiedKFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- do two different set for standardization and normalization for sake of comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_x= StandardScaler()\n",
    "X_train_standard = st_x.fit_transform(X_train) \n",
    "X_test_standard = st_x.fit_transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_x = MinMaxScaler()\n",
    "X_train_norm = norm_x.fit_transform(X_train)\n",
    "X_test_norm = norm_x.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4\n",
    "specifying the model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 50\n",
    "\n",
    "methods = {\n",
    "#     'Lasso':LogisticRegression(penalty=\"l1\",C=100, random_state=1234, max_iter=300, solver=\"liblinear\"),\n",
    "#     'NaiveBayes':GaussianNB(),\n",
    "#     'k-NN(5)':KNeighborsClassifier(n_neighbors=5, algorithm='kd_tree'),\n",
    "    'Decision Tree':DecisionTreeClassifier(max_depth=None),\n",
    "#     'Bagging(Tree)':BaggingClassifier(DecisionTreeClassifier(max_depth=3),n_estimators=n_estimators),\n",
    "#     'Bagging(kNN)':BaggingClassifier(KNeighborsClassifier(n_neighbors=10, algorithm='kd_tree'),n_estimators=n_estimators),\n",
    "#     'Random Forest':RandomForestClassifier(n_estimators=n_estimators,max_depth=3,oob_score=True),\n",
    "#     'Extremely Randomized Trees':ExtraTreesClassifier(n_estimators=n_estimators,max_depth=3),\n",
    "#     'Ada Boost':AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),n_estimators=n_estimators)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desision Tree\n",
    "here we do three different comparisions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Decision Tree\n",
      "========================================\n",
      "\t  Accuracy (CV) 0.996 0.000\n",
      "\tAccuracy (Test) 0.517\n",
      "\t      Precision 0.517\n",
      "\t      Recall    0.468\n",
      "\t      F1        0.492\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(methods, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Decision Tree\n",
      "========================================\n",
      "\t  Accuracy (CV) 0.996 0.000\n",
      "\tAccuracy (Test) 0.269\n",
      "\t      Precision 0.269\n",
      "\t      Recall    0.401\n",
      "\t      F1        0.322\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(methods, X_train_standard,y_train, X_test_standard, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Decision Tree\n",
      "========================================\n",
      "\t  Accuracy (CV) 0.996 0.000\n",
      "\tAccuracy (Test) 0.219\n",
      "\t      Precision 0.219\n",
      "\t      Recall    0.263\n",
      "\t      F1        0.239\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(methods, X_train_norm,y_train, X_test_norm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result \n",
    "based on these three evaluation normalization is not a good approach for tree if we want to use tree we have to think of better cleaning the features. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
